{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AWS S3 CRUD w. Boto3 & Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AWS Access Key ID: AKIAZVMTVFYLQIY2FOHH\n",
      "AWS Secret Access Key: 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\n",
      "Region: eu-central-1\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the AWS credentials and region from environment variables\n",
    "aws_access_key_id = os.getenv(\"AWS_ACCESS_KEY_ID\")\n",
    "aws_secret_access_key = os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n",
    "region_name = os.getenv(\"AWS_DEFAULT_REGION\")\n",
    "\n",
    "print(f\"AWS Access Key ID: {aws_access_key_id}\")\n",
    "print(f\"AWS Secret Access Key: {aws_secret_access_key}\")\n",
    "print(f\"Region: {region_name}\")\n",
    "\n",
    "region_name = \"us-east-1\"\n",
    "endpoint_url = f\"https://s3.{region_name}.amazonaws.com\"\n",
    "# instantiate boto3 resource for AWS S3 and name bucket\n",
    "s3 = boto3.resource(\n",
    "    \"s3\",\n",
    "    region_name=region_name,\n",
    "    endpoint_url=endpoint_url,\n",
    "    aws_access_key_id=aws_access_key_id,\n",
    "    aws_secret_access_key=aws_secret_access_key,\n",
    ")\n",
    "bucket_name = \"aws-s3-crud-bucket\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'all_my_buckets': ['aws-s3-crud-bucket']}\n",
      "Bucket aws-s3-crud-bucket already exists\n"
     ]
    }
   ],
   "source": [
    "# check if bucket exists\n",
    "# create the bucket if it does not exists\n",
    "all_my_buckets = [bucket.name for bucket in s3.buckets.all()]\n",
    "print({\"all_my_buckets\": all_my_buckets})\n",
    "\n",
    "if bucket_name not in all_my_buckets:\n",
    "    bucket = s3.create_bucket(Bucket=bucket_name) \n",
    "    print(f\"Bucket {bucket_name} created successfully\")\n",
    "else:\n",
    "    print(f\"Bucket {bucket_name} already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File sample.txt uploaded to bucket aws-s3-crud-bucket\n"
     ]
    }
   ],
   "source": [
    "# upload a file to the bucket\n",
    "file_path = \"sample.txt\"\n",
    "file_name = os.path.basename(file_path)\n",
    "s3.Bucket(bucket_name).upload_file(file_path, file_name)\n",
    "print(f\"File {file_name} uploaded to bucket {bucket_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contents of file sample.txt: lorem ipsum dolor sit amet, consectetur adipiscing elit sed do eiusmod tempor incididunt ut labore et dolore magna aliqua ut enim ad minim veniam quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur excepteur sint occaecat cupidatat non proident sunt in culpa qui officia deserunt mollit anim id est laborum\n"
     ]
    }
   ],
   "source": [
    "# read and print the contents of the file\n",
    "obj = s3.Object(bucket_name, file_name)\n",
    "response = obj.get()\n",
    "data = response[\"Body\"].read().decode(\"utf-8\")\n",
    "print(f\"Contents of file {file_name}: {data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contents of file sample.txt updated successfully\n"
     ]
    }
   ],
   "source": [
    "# update content of sample.txt with new content from update-sample.txt\n",
    "new_content_file_path = \"update-sample.txt\"\n",
    "s3.Object(bucket_name, file_name).put(Body=open(new_content_file_path, \"rb\"))\n",
    "print(f\"Contents of file {file_name} updated successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contents of file sample.txt: UPDATED CONTENT\n"
     ]
    }
   ],
   "source": [
    "# read and print the contents of the file\n",
    "response = obj.get()\n",
    "data = response[\"Body\"].read().decode(\"utf-8\")\n",
    "print(f\"Contents of file {file_name}: {data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File sample.txt deleted successfully\n"
     ]
    }
   ],
   "source": [
    "# delete the file from the bucket\n",
    "obj.delete()\n",
    "print(f\"File {file_name} deleted successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket aws-s3-crud-bucket deleted successfully\n"
     ]
    }
   ],
   "source": [
    "# delete the bucket\n",
    "bucket = s3.Bucket(bucket_name)\n",
    "bucket.objects.all().delete()\n",
    "bucket.delete()\n",
    "print(f\"Bucket {bucket_name} deleted successfully\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
